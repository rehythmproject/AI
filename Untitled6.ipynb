{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdVR21K_TgAq",
        "outputId": "fc79d4c0-f3b1-4e3f-9c08-d734f98301f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 김유진 PM 오늘 회의는 각 분야별로 필요한 솔루션을 논의하고 피드백을 나누는 시간을 갖도록 하겠습니다.\n",
            "먼저 프론트앤드 부분부터 이야기해 볼까요?\n",
            "네, 프론트앤드에서는 사용자 경험이 매우 중요한 요소입니다.\n",
            "저는 리액트를 사용해서 컴포넌트 기반으로 UI를 개발하는 것이 좋을 것 같습니다.\n",
            "css나 material, ui 같은 css 프레임워크도 고려하고 있어요.\n",
            "이 지훈 100엔드 개발자 프론트엔드에서 리액트를 사용하면 API 요청이 많아질텐데 100엔드에서 그걸 처리하는 부분이 중요할 것 같습니다 그래서 100엔드에서는  랫스프 풀 API를 제공하는 구조로 잡는게 좋겠다고 생각해요 특히 비동기 처리를 효율적으로 할 수 있어서 리액트와 잘 맞을 것 같습니다 솜화 나 데이터 베이스 전문가 API 요청이 많아질 걸 고려하면  데이터베이스 선택도 중요하겠네요.\n",
            "저는 관계형 데이터베이스임 포스트그레스 크랜을 제안하고 싶어요.\n",
            "스케일링이 필요하다면 노스크엘임 몽고두부와 혼용하는 것도 고려해볼 수 있습니다.\n",
            "보안적인 부분도 중요한데 특히 인증 부분을 강화할 필요가 있습니다.\n",
            "데이터 전송을 암호화하고 서버 측에서는 기본적인 보안 규칙을 모두 따르는 게 중요합니다.\n",
            "김유진, PM 좋습니다.\n",
            "프론트 앤드, 백 앤드, 데이터 베이스 보안 모두 큰 틀에서 방향이 잡힌 것 같아요.\n",
            "혹시 추가적인 의견이나 고려할 사항이 있을까요?\n",
            "그리고 노드  플라이웨이 나 리퀴베이스 같은 툴을 고려해보죠.\n",
            "데이터베이스는 포스트그레스ク웨어는 기본으로 하되 필요시 모형을 사용하여  동고들 부와의 혼용도 고려하며 플라이웨이 같은 마이그레이션 도구를 사용한다.\n",
            "보안은 oas 2.\n",
            "0과 JWT를 기반으로 강화하고, HTTPS를 기반으로 한다.\n",
            "내용을 바탕으로 다음 회의 때까지 각 분야별 세부 설계를 진행해주시면 좋겠습니다.\n",
            "\n",
            "Transcription complete. Result saved to formatted_text.txt\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers huggingface_hub\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=\"토큰 입력하세요.\")\n",
        "\n",
        "import torchaudio\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import re\n",
        "\n",
        "audio_file = \"/content/development_meeting_script.wav\"\n",
        "\n",
        "model_name = \"openai/whisper-medium\"\n",
        "processor = WhisperProcessor.from_pretrained(model_name)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "audio_input, sample_rate = torchaudio.load(audio_file)\n",
        "\n",
        "# 오디오 청크 처리 함수\n",
        "def transcribe_chunk(audio_chunk):\n",
        "    input_features = processor(\n",
        "        audio_chunk.squeeze(0),\n",
        "        sampling_rate=16000,\n",
        "        return_tensors=\"pt\",\n",
        "        language=\"ko\"\n",
        "    ).input_features\n",
        "    generated_ids = model.generate(input_features, max_new_tokens=300)\n",
        "    transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "    return transcription[0]\n",
        "\n",
        "# 청크 길이 설정\n",
        "chunk_length = int(20 * sample_rate)\n",
        "num_chunks = (audio_input.shape[1] + chunk_length - 1) // chunk_length\n",
        "\n",
        "full_transcription = []\n",
        "\n",
        "for i in range(num_chunks):\n",
        "    start = i * chunk_length\n",
        "    end = min((i + 1) * chunk_length, audio_input.shape[1])\n",
        "    audio_chunk = audio_input[:, start:end]\n",
        "    transcription = transcribe_chunk(audio_chunk)\n",
        "    full_transcription.append(transcription)\n",
        "\n",
        "text = \" \".join(full_transcription)\n",
        "formatted_text = re.sub(r'([.!?])\\s*', r'\\1\\n', text)\n",
        "\n",
        "print(formatted_text)\n",
        "\n",
        "with open(\"/content/formatted_text.txt\", \"w\") as f:\n",
        "    f.write(formatted_text)\n",
        "\n",
        "print(\"Transcription complete. Result saved to formatted_text.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torchaudio jiwer\n",
        "\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "from jiwer import wer\n",
        "\n",
        "model_name = \"openai/whisper-medium\"\n",
        "processor = WhisperProcessor.from_pretrained(model_name)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "audio_file = \"/content/development_meeting_script.wav\"\n",
        "audio_input, sample_rate = torchaudio.load(audio_file)\n",
        "\n",
        "resampler = T.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "audio_input_resampled = resampler(audio_input)\n",
        "\n",
        "def evaluate_pronunciation(audio_chunk, expected_transcription):\n",
        "    input_features = processor(\n",
        "        audio_chunk.squeeze(0),\n",
        "        sampling_rate=16000,\n",
        "        return_tensors=\"pt\"\n",
        "    ).input_features\n",
        "    generated_ids = model.generate(input_features)\n",
        "    transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    error_rate = wer(expected_transcription, transcription)\n",
        "    return transcription, error_rate\n",
        "\n",
        "# 기대하는 발음 텍스트\n",
        "expected = \"\"\"\n",
        "김유진 PM: 오늘 회의는 각 분야별로 필요한 솔루션을 논의하고 피드백을 나누는 시간을 갖도록 하겠습니다. 먼저 프론트엔드 부분부터 이야기해 볼까요?\n",
        "\n",
        "프론트엔드 개발자: 네, 프론트엔드에서는 사용자 경험이 매우 중요한 요소입니다. 저는 React를 사용해서 컴포넌트 기반으로 UI를 개발하는 것이 좋을 것 같습니다. CSS나 Material UI 같은 CSS 프레임워크도 고려하고 있습니다.\n",
        "\n",
        "이지훈, 백엔드 개발자: 프론트엔드에서 React를 사용하면 API 요청이 많아질 텐데, 백엔드에서 그걸 처리하는 부분이 중요할 것 같습니다. 그래서 백엔드에서는 RESTful API를 제공하는 구조로 잡는 게 좋겠다고 생각해요. 특히 비동기 처리를 효율적으로 할 수 있어서 React와 잘 맞을 것 같습니다.\n",
        "\n",
        "솜화, 데이터베이스 전문가: API 요청이 많아질 걸 고려하면 데이터베이스 선택도 중요하겠네요. 저는 관계형 데이터베이스로 PostgreSQL을 제안하고 싶어요. 스케일링이 필요하다면 NoSQL인 MongoDB와 혼용하는 것도 고려해볼 수 있습니다.\n",
        "\n",
        "보안 전문가: 보안적인 부분도 중요한데 특히 인증 부분을 강화할 필요가 있습니다. 데이터 전송을 암호화하고, 서버 측에서는 기본적인 보안 규칙을 모두 따르는 게 중요합니다.\n",
        "\n",
        "김유진, PM: 좋습니다. 프론트엔드, 백엔드, 데이터베이스, 보안 모두 큰 틀에서 방향이 잡힌 것 같아요. 혹시 추가적인 의견이나 고려할 사항이 있을까요? 그리고 Flyway나 Liquibase 같은 툴을 고려해보죠. 데이터베이스는 PostgreSQL을 기본으로 하되 필요 시 MongoDB와의 혼용도 고려하며 Flyway 같은 마이그레이션 도구를 사용할 수 있습니다. 보안은 OAuth 2.0과 JWT를 기반으로 강화하고, HTTPS를 기반으로 합니다.\n",
        "\n",
        "김유진, PM: 내용을 바탕으로 다음 회의 때까지 각 분야별 세부 설계를 진행해주시면 좋겠습니다.\n",
        "\"\"\"\n",
        "\n",
        "audio_chunk = audio_input_resampled[:, :int(audio_input_resampled.shape[1])]\n",
        "transcription, error_rate = evaluate_pronunciation(audio_chunk, expected)\n",
        "\n",
        "print(\"Transcription:\", transcription)\n",
        "print(\"Pronunciation Error Rate:\", error_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXDoIWpF6YIZ",
        "outputId": "d10ac5a2-2374-427f-f51b-7956c51e99a5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.5.1+cu121)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\n",
            "Transcription:  김유진 PM 오늘 회의는 각 분야별로 필요한 솔루션을 논의하고 피드백을 나누는 시간을 갖도록 하겠습니다. 먼저 프론트앤드 부분부터 이야기해 볼까요?\n",
            "Pronunciation Error Rate: 0.914572864321608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NnYXDF6c6ZHd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}